{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要なインポートを実施\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "from pandas import Series,DataFrame\n",
    "from datetime import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 競馬情報の取得をWebスクレイピングで実施\n",
    "\n",
    "# URLからコンテンツを取得する\n",
    "def url_to_soup(url):\n",
    "    req = requests.get(url)\n",
    "    return BeautifulSoup(req.content, 'html.parser')\n",
    "\n",
    "# 各馬の過去１０レースリンクを取得\n",
    "def horse_page_link(url):\n",
    "    soup = url_to_soup(url)\n",
    "    link_list = [HOME_URL + x.get('href') for x in soup.find_all('a', class_='tx-mid tx-low') ]\n",
    "    return link_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018年8月23\n",
      "不\n",
      "900\n",
      "2018-08-23 00:00:00\n"
     ]
    }
   ],
   "source": [
    "tag_to_text = lambda x: p.sub(\"\", x).split('\\n') \n",
    "split_tr = lambda x: str(x).split('</tr>')\n",
    "\n",
    "def get_previous_race_row(soup):\n",
    "    race_table = soup.select(\"table.tb01\")[2]\n",
    "    return [tag_to_text(x)  for x in split_tr(race_table)]\n",
    "\n",
    "def horse_data(url, race_date):\n",
    "    soup = url_to_soup(url)\n",
    "\n",
    "    # 過去のレースデータ\n",
    "    pre_race_data = get_previous_race_row(soup)\n",
    "    df = pd.DataFrame(pre_race_data)[1:][[2,3,10,11,13,14,15,19,23]].dropna().rename(columns={\n",
    "        2:'date', 3:'place', 10:'len', 11:'wether', 13:'popularity', 14:'rank', 15:'time',19:'weight',23:'money'})\n",
    "    return df\n",
    "\n",
    "def result_data(url):\n",
    "    soup = url_to_soup(url)\n",
    "\n",
    "    # 土の状態\n",
    "    condition = soup.find(id=\"race-data02\").get_text().replace('\\n','').split(';')[1].split('　')[2][0:1]\n",
    "\n",
    "    # レースの長さ\n",
    "    race_len = int(soup.find(id=\"race-data01-a\").get_text().replace('\\n','').split('　')[3].replace(',','')[1:4])\n",
    "\n",
    "    # 過去のレースの1位を正解ラベルとして取得する\n",
    "    hukusyo_list = []\n",
    "    hukusyo_list.append(int(p.sub(\"\", str(soup.find_all('tr', class_='bg-1chaku')[0]).split('</td>')[2]).replace('\\n','') ))\n",
    "\n",
    "    # レース日\n",
    "    race_date_str = soup.find(id=\"race-data01-a\").get_text().replace('\\n','').split(';')[0].split('日')[0]\n",
    "    print(race_date_str)\n",
    "    race_date = dt.strptime(race_date_str, '%Y年%m月%d')\n",
    "    return hukusyo_list, condition, race_len, race_date\n",
    "\n",
    "a, b, c, d = result_data('https://www.nankankeiba.com/race_info/2018082321060403.do')\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 馬場状態のカラム内容を文字列によって変更する\n",
    "def add_soil_columns(row):\n",
    "        row['soil_heavy'] = 1 if row['wether'][-2:] =='/重'  else 0\n",
    "        row['soil_s_heavy'] = 1 if row['wether'][-2:] =='稍重'  else 0\n",
    "        row['soil_good'] = 1 if row['wether'][-2:] =='/良'  else 0\n",
    "        row['soil_bad'] = 1 if row['wether'][-2:] =='不良'  else 0\n",
    "        return row\n",
    "\n",
    "# レースデータのカラムを加工\n",
    "def add_race_data(df):\n",
    "    df_ =pd.DataFrame()\n",
    "    for idx, row in df.iterrows():\n",
    "        if row['popularity'] == '':\n",
    "            continue\n",
    "\n",
    "        # 馬場状態\n",
    "        row = add_soil_columns(row)\n",
    "\n",
    "        row['money']=int(row['money'].replace(',','')) \n",
    "        row['horse_cnt'] = int(row['rank'].split('/')[1])\n",
    "        row['result_rank'] = int(row['rank'].split('/')[0])\n",
    "        row['len'] = int(row['len'][0:4])\n",
    "        row['popularity'] = int(row['popularity'])\n",
    "        row['weight'] = int(row['weight'])\n",
    "\n",
    "        # 　競馬場の一致\n",
    "        row['same_place'] = 1 if row['place'].startswith(PLACE)  else 0\n",
    "\n",
    "        # タイム(秒)\n",
    "        try:\n",
    "            time = datetime.datetime.strptime(row['time'], '%M:%S.%f')\n",
    "            row['sec'] = time.minute*60 + time.second + time.microsecond/1000000 \n",
    "        except ValueError:\n",
    "            time = datetime.datetime.strptime(row['time'], '%S.%f')\n",
    "            row['sec'] = time.second + time.microsecond/1000000\n",
    "\n",
    "        row['sec'] = int(row['sec']) \n",
    "\n",
    "        df_ = df_.append(row, ignore_index=True)\n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
